{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-01T09:07:54.639244Z",
     "start_time": "2022-06-01T09:07:54.631077Z"
    }
   },
   "source": [
    "# DCGAN128 for fetal head ultrasound images\n",
    "\n",
    "**Author(s)**: Thea Bautista [@theabautista](https://github.com/theabautista)     \n",
    "**Contributor(s)**:  Miguel Xochicale [@mxochicale](https://github.com/mxochicale)     \n",
    "\n",
    "May2022\n",
    "\n",
    "\n",
    "## Summary\n",
    "This notebook presents a learning pipeline to classify 4 chamber view from echocardiography datasets.\n",
    "\n",
    "### How to run the notebook\n",
    "\n",
    "1. Go to the repository path: `cd $HOME/repositories/xfetus/miua2022`\n",
    "2. Open repo in pycharm and in the terminal type:\n",
    "    ```\n",
    "    git checkout master # or the branch\n",
    "    git pull # to bring a local branch up-to-date with its remote version\n",
    "    ```\n",
    "3. Launch Notebook server  \n",
    "    Go to notebooks path: `cd $HOME/repositories/xfetus/miua2022/notebooks` and type in the pycharm terminal:\n",
    "    ```\n",
    "    conda activate susiE \n",
    "    jupyter notebook\n",
    "    ```\n",
    "    which will open your web-browser.\n",
    "    \n",
    "    \n",
    "### References\n",
    "* \"Proposed Regulatory Framework for Modifications to Artificial Intelligence/Machine Learning (AI/ML)-Based Software as a Medical Device (SaMD) - Discussion Paper and Request for Feedback\". https://www.fda.gov/media/122535/download \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fkAY8l49nn7f"
   },
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NU6swrdknh9B"
   },
   "outputs": [],
   "source": [
    "!pip install pytorch-gan-metrics\n",
    "!pip install --quiet \"torchmetrics>=0.3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ox_mR0B-nh9F",
    "outputId": "b83de654-536d-4aa7-f719-b6acf83fe305"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "#%matplotlib inline\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.utils.data\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "import torch.nn as nn\n",
    "from torch import optim as optim\n",
    "import numpy as np\n",
    "import torchvision.utils as vutils\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "from torchmetrics import Accuracy\n",
    "from pytorch_gan_metrics import get_inception_score_and_fid\n",
    "from PIL import Image\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "manualSeed = 999\n",
    "#manualSeed = random.randint(1, 10000) # use if you want new results\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "acO14Rk-pPLm"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IvPsW_Gnnh9G"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9DdxQ5PS1-9e"
   },
   "outputs": [],
   "source": [
    "!unzip '../head_cirumference.zip'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fFiySWzcnx60"
   },
   "source": [
    "##Â Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ySepmguMjhQI"
   },
   "outputs": [],
   "source": [
    "!cd '../DC-GANS/results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dO0D8y4Inh9H"
   },
   "outputs": [],
   "source": [
    "# Batch size\n",
    "batch_size = 10\n",
    "\n",
    "# Training image size\n",
    "image_size = 128\n",
    "\n",
    "# Number of channels in image\n",
    "nc = 1\n",
    "\n",
    "# Size of z latent vector (i.e. size of generator input)\n",
    "nz = 128\n",
    "\n",
    "# Size of feature maps in generator\n",
    "ngf = 128\n",
    "\n",
    "# Size of feature maps in discriminator\n",
    "ndf = 128\n",
    "\n",
    "# Number of training epochs\n",
    "num_epochs = 1000\n",
    "\n",
    "# Learning rate for optimizers\n",
    "lr = 0.0002\n",
    "\n",
    "# Number of GPUs available. Use 0 for CPU mode.\n",
    "ngpu = 1\n",
    "\n",
    "# Size of training set\n",
    "subset_size=100\n",
    "\n",
    "# Checkpoint path\n",
    "checkpoint_path = \"../results/DCGAN128/100_train.pt\"\n",
    "\n",
    "# Dataset path\n",
    "data_path = '/content/head_cirumference'\n",
    "\n",
    "# Degrees of rotation\n",
    "degrees_of_rot=10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fv9B573ZP0TM"
   },
   "source": [
    "## Defining transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UHI7sD5ynh9I"
   },
   "outputs": [],
   "source": [
    "\n",
    "train_dataset = datasets.ImageFolder(\n",
    "    root=data_path,\n",
    "    transform=transforms.Compose([transforms.ToTensor(),\n",
    "                                  transforms.Grayscale(),\n",
    "                                  transforms.Normalize((0.5,), (0.5,)), \n",
    "                                  transforms.Resize((image_size,image_size)),\n",
    "                                  transforms.RandomHorizontalFlip(),\n",
    "                                  transforms.RandomRotation(degrees_of_rot)\n",
    "    ]))\n",
    "\n",
    "train_data_subset = torch.utils.data.Subset(train_dataset, np.random.choice(len(train_dataset), subset_size, replace=False))\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    train_data_subset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pFZ_juUenh9J",
    "outputId": "59da2f89-1005-4800-a983-ec3320b5ecff"
   },
   "outputs": [],
   "source": [
    "num_batches = len(dataloader)\n",
    "print(\"Number of batches: \",num_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mm18tGMtnh9J"
   },
   "source": [
    "## Display image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 303
    },
    "id": "DYk4gmDsnh9L",
    "outputId": "43b580cb-f0ea-46c2-d33e-bc17838eabf8"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "for x,_ in dataloader:\n",
    "    plt.imshow(x.numpy()[0][0], cmap='gray')\n",
    "    print(x.numpy()[0][0].shape)\n",
    "    print(x.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MDY6eE6Yn35F"
   },
   "source": [
    "## Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zUVjc0tgnh9M"
   },
   "outputs": [],
   "source": [
    "def weights_init(model):\n",
    "    classname = model.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(model.weight.data, 0.0, 0.002)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(model.weight.data, 1.0, 0.002)\n",
    "        nn.init.constant_(model.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7p5bt41Nnh9N"
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Generator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            # input is Z, going into a convolution\n",
    "            nn.ConvTranspose2d( nz, ngf * 16, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 16),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*16) x 4 x 4\n",
    "            nn.ConvTranspose2d(ngf * 16, ngf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*8) x 8 x 8\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*4) x 16 x 16 \n",
    "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*2) x 32 x 32\n",
    "            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf) x 64 x 64\n",
    "            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # state size. (nc) x 128 x 128\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QooU7Sgan5l9"
   },
   "source": [
    "## Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iIDK42Jtnh9O"
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            # input is (nc) x 128 x 128\n",
    "            nn.Conv2d(nc, ndf, 4, stride=2, padding=1, bias=False), \n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf) x 64 x 64\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*2) x 32 x 32\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*4) x 16 x 16 \n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*8) x 8 x 8\n",
    "            nn.Conv2d(ndf * 8, ndf * 16, 4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 16),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*16) x 4 x 4\n",
    "            nn.Conv2d(ndf * 16, 1, 4, stride=1, padding=0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "            # state size. 1\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QumVQivvn7X5"
   },
   "source": [
    "## Initialise network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZAA41JrjrMx1"
   },
   "outputs": [],
   "source": [
    "def save_checkpoint(state, output_file='../results/DCGAN128/100_training.pt'):\n",
    "  \"\"\"Function which saves a checkpoint containing model state into a file\"\"\"\n",
    "  print(\"Saving checkpoint at epoch : \", state['epoch']-1)\n",
    "  torch.save(state, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pV78JYyenh9O"
   },
   "outputs": [],
   "source": [
    "# Create the generator\n",
    "netG = Generator(ngpu).to(device)\n",
    "netD = Discriminator(ngpu).to(device)\n",
    "\n",
    "# Handle multi-gpu if desired\n",
    "if (device.type == 'cuda') and (ngpu > 1):\n",
    "    netG = nn.DataParallel(netG, list(range(ngpu)))\n",
    "    netD = nn.DataParallel(netD, list(range(ngpu)))\n",
    "\n",
    "# Apply the weights_init function to randomly initialize all weights\n",
    "#  to mean=0, stdev=0.02.\n",
    "netG.apply(weights_init)\n",
    "netD.apply(weights_init)\n",
    "\n",
    "# Print the model\n",
    "print(netG)\n",
    "print(netD)\n",
    "\n",
    "# Initialize BCELoss function\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Create batch of latent vectors that we will use to visualize\n",
    "#  the progression of the generator\n",
    "fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n",
    "\n",
    "# Establish convention for real and fake labels during training\n",
    "real_label = 0.9\n",
    "fake_label = 0.\n",
    "\n",
    "# Hyperparameters\n",
    "gen_lr = 2e-3\n",
    "dis_lr = 2e-4\n",
    "\n",
    "wd_gen = 1e-2\n",
    "wd_dis = 1e-1\n",
    "\n",
    "beta1 = 0.5\n",
    "\n",
    "# Setup Adam optimizers for both G and D\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=gen_lr, betas=(beta1, 0.999), weight_decay=wd_gen)\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=dis_lr, betas=(beta1, 0.999), weight_decay=wd_gen)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ILYxrWUZoAS7"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "wC_P8kGYnh9Q",
    "outputId": "41f6bbd8-38e2-4642-b704-fbe1297bf827"
   },
   "outputs": [],
   "source": [
    "# Training Loop\n",
    "last_epoch = 0\n",
    "load_checkpoint = False\n",
    "\n",
    "# Lists to keep track of progress\n",
    "img_list = []\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "D_acc_real = []\n",
    "D_acc_gen = []\n",
    "\n",
    "\n",
    "if load_checkpoint:\n",
    "    print(f\"loading checkpoint {checkpoint_path}\")\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    last_epoch = checkpoint['epoch']\n",
    "    netG.load_state_dict(checkpoint['modelG_state_dict'])\n",
    "    netD.load_state_dict(checkpoint['modelD_state_dict'])\n",
    "    optimizerG.load_state_dict(checkpoint['optimizerG_state_dict'])\n",
    "    optimizerD.load_state_dict(checkpoint['optimizerD_state_dict'])\n",
    "    G_losses = checkpoint['G_losses']\n",
    "    D_losses = checkpoint['D_loss']\n",
    "    D_acc_real = checkpoint['D_acc_real']\n",
    "    D_acc_gen = checkpoint['D_acc_gen']\n",
    "\n",
    "netG.train()\n",
    "netD.train()\n",
    "\n",
    "iters = 0\n",
    "accuracy = Accuracy().to(device)\n",
    "print(\"Starting Training Loop...\")\n",
    "# For each epoch\n",
    "for epoch in range(last_epoch,num_epochs):\n",
    "    # For each batch in the dataloader\n",
    "    G_losses_tmp = []\n",
    "    D_losses_tmp = []\n",
    "    d_acc_real_tmp = []\n",
    "    d_acc_gen_tmp = []\n",
    "    \n",
    "\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "\n",
    "        ######################\n",
    "        # Update discriminator\n",
    "        ######################\n",
    "        # Set all gradients to zero\n",
    "        netD.zero_grad()\n",
    "        # moving real data to gpu\n",
    "        real_cpu = data[0].to(device)\n",
    "        # size of current batch\n",
    "        b_size = real_cpu.size(0)\n",
    "        # initialising labels for real data\n",
    "        label = torch.full((b_size,), real_label, dtype=torch.float, device=device)\n",
    "        # forward pass real data through D\n",
    "        output = netD(real_cpu).view(-1)\n",
    "        # calculate loss on real batch\n",
    "        errD_real = criterion(output, label)\n",
    "        # calculate accuracy on real batch\n",
    "        label_tmp = label.int()\n",
    "        d_acc_real_tmp.append(accuracy(output, label_tmp))\n",
    "        # backpropagate\n",
    "        errD_real.backward()\n",
    "        D_x = output.mean().item()\n",
    "\n",
    "        ## Train with all-fake batch\n",
    "        # batch of latent vectors\n",
    "        noise = torch.randn(b_size, nz, 1, 1, device=device)\n",
    "        # get fake images\n",
    "        fake = netG(noise)\n",
    "        # get fake labels\n",
    "        label.fill_(fake_label)\n",
    "        # forward pass with fake data\n",
    "        output = netD(fake.detach()).view(-1)\n",
    "        # calculate loss on fake batch\n",
    "        errD_fake = criterion(output, label)\n",
    "        # backpropagate\n",
    "        errD_fake.backward()\n",
    "        D_G_z1 = output.mean().item()\n",
    "        # calculate total error of discriminator\n",
    "        errD = errD_real + errD_fake\n",
    "        # compute accuracy on fake images\n",
    "        d_acc_gen_tmp.append(accuracy(output, label.int()))\n",
    "        # update D\n",
    "        optimizerD.step()\n",
    "\n",
    "        ##################\n",
    "        # Update generator\n",
    "        ##################\n",
    "        netG.zero_grad()\n",
    "        label.fill_(real_label)  # fake labels are real for generator cost\n",
    "        # Since we just updated D, perform another forward pass of fake batch through D\n",
    "        output = netD(fake).view(-1)\n",
    "        # calculate generator loss\n",
    "        errG = criterion(output, label)\n",
    "        # backpropagate\n",
    "        errG.backward()\n",
    "        D_G_z2 = output.mean().item()\n",
    "        # Update G\n",
    "        optimizerG.step()\n",
    "\n",
    "        # Output training stats\n",
    "        if i % 50 == 0:\n",
    "            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
    "                  % (epoch, num_epochs, i, len(dataloader),\n",
    "                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
    "            with torch.no_grad():\n",
    "                generated_data = netG(noise).cpu().view(b_size, 64,64)\n",
    "                for x in generated_data:\n",
    "                    plt.imshow(x.detach().numpy(), interpolation='nearest',cmap='gray')\n",
    "                    plt.show()\n",
    "                    plt.savefig(\"/\")\n",
    "                    break\n",
    "\n",
    "        # Save losses for plotting later\n",
    "        G_losses_tmp.append(errG.item())\n",
    "        D_losses_tmp.append(errD.item())\n",
    "\n",
    "        # Check how the generator is doing by saving G's output on fixed_noise\n",
    "        if (iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len(dataloader)-1)):\n",
    "            with torch.no_grad():\n",
    "                fake = netG(fixed_noise).detach().cpu()\n",
    "            img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n",
    "\n",
    "        iters += 1\n",
    "\n",
    "    \n",
    "    # Save accuracy of discriminator\n",
    "    D_acc_real.append(torch.mean(torch.Tensor(d_acc_real_tmp)))\n",
    "    D_acc_gen.append(torch.mean(torch.Tensor(d_acc_gen_tmp)))\n",
    "    \n",
    "    # Save Losses for plotting later\n",
    "    G_losses.append(torch.mean(torch.Tensor(G_losses_tmp)))\n",
    "    D_losses.append(torch.mean(torch.Tensor(D_losses_tmp)))\n",
    "\n",
    "    print(f'[{epoch}/{num_epochs}] G_loss: {G_losses[-1]}, D_loss: {D_losses[-1]}')\n",
    "\n",
    "    # save checkpoint\n",
    "    if (epoch+1) % 5 == 0:\n",
    "        checkpoint = {\n",
    "          'epoch': epoch+1,\n",
    "          'modelG_state_dict': netG.state_dict(),\n",
    "          'modelD_state_dict': netD.state_dict(),\n",
    "          'optimizerG_state_dict': optimizerG.state_dict(),\n",
    "          'optimizerD_state_dict': optimizerD.state_dict(),\n",
    "          'G_losses': G_losses,\n",
    "          'D_loss': D_losses,\n",
    "          'D_acc_real': D_acc_real,\n",
    "          'D_acc_gen': D_acc_gen\n",
    "        }\n",
    "        save_checkpoint(checkpoint, checkpoint_path)\n",
    "        if epoch+1 in [300, 500, 800, 1000]:\n",
    "            checkpoint_filename = f'../results/DCGAN64/org_params/800_train_subset_{epoch+1}_epochs.pt'\n",
    "            save_checkpoint(checkpoint, checkpoint_filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zqeQ3Hn7oFDN"
   },
   "source": [
    "## Plotting figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "iRjkMC551o83",
    "outputId": "0bd0f2a7-d475-423e-ad24-def034d37b44"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,5))\n",
    "plt.title(\"Generator and Discriminator Loss During Training\")\n",
    "plt.plot(G_losses,label=\"Generator\")\n",
    "plt.plot(D_losses,label=\"Discriminator\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"BCE Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "trCH2QjGnh9R",
    "outputId": "a33deae8-4230-451b-9d0e-1ba94f5ed6e9"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,5))\n",
    "plt.title(\"Accuracy of Discriminator\")\n",
    "plt.plot(D_acc_gen,label=\"Accuracy on generated images\")\n",
    "plt.plot(D_acc_real,label=\"Accuracy on real images\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "dcgan128_for_ultrasounds.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
