# 
## Citations
53
https://scholar.google.com/scholar?cites=1775075409962294914&as_sdt=2005&sciodt=0,5&hl=en
Retrived
Thu 26 Aug 22:13:16 BST 2021

## Authors 

## Notes

## Links 

https://arxiv.org/pdf/1707.05392.pdf

## Bibtex 

@InProceedings{10.1007/978-3-319-67564-0_11,
author="Hu, Yipeng
and Gibson, Eli
and Lee, Li-Lin
and Xie, Weidi
and Barratt, Dean C.
and Vercauteren, Tom
and Noble, J. Alison",
editor="Cardoso, M. Jorge
and Arbel, Tal
and Gao, Fei
and Kainz, Bernhard
and van Walsum, Theo
and Shi, Kuangyu
and Bhatia, Kanwal K.
and Peter, Roman
and Vercauteren, Tom
and Reyes, Mauricio
and Dalca, Adrian
and Wiest, Roland
and Niessen, Wiro
and Emmer, Bart J.",
title="Freehand Ultrasound Image Simulation with Spatially-Conditioned Generative Adversarial Networks",
booktitle="Molecular Imaging, Reconstruction and Analysis of Moving Body Organs, and Stroke Imaging and Treatment",
year="2017",
publisher="Springer International Publishing",
address="Cham",
pages="105--115",
isbn="978-3-319-67564-0"
}



abstract="Sonography synthesis has a wide range of applications, including medical procedure simulation, clinical training and multimodality image registration. In this paper, we propose a machine learning approach to simulate ultrasound images at given 3D spatial locations (relative to the patient anatomy), based on conditional generative adversarial networks (GANs). In particular, we introduce a novel neural network architecture that can sample anatomically accurate images conditionally on spatial position of the (real or mock) freehand ultrasound probe. To ensure an effective and efficient spatial information assimilation, the proposed spatially-conditioned GANs take calibrated pixel coordinates in global physical space as conditioning input, and utilise residual network units and shortcuts of conditioning data in the GANs' discriminator and generator, respectively. Using optically tracked B-mode ultrasound images, acquired by an experienced sonographer on a fetus phantom, we demonstrate the feasibility of the proposed method by two sets of quantitative results: distances were calculated between corresponding anatomical landmarks identified in the held-out ultrasound images and the simulated data at the same locations unseen to the networks; a usability study was carried out to distinguish the simulated data from the real images. In summary, we present what we believe are state-of-the-art visually realistic ultrasound images, simulated by the proposed GAN architecture that is stable to train and capable of generating plausibly diverse image samples.",

